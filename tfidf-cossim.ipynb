{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_forums_posts_text.data', 'rb') as file:\n",
    "    posts_text = pickle.load(file)\n",
    "\n",
    "# TFIDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=True, max_df=0.5, min_df=2, ngram_range=(1,2), max_features=10000)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(posts_text)\n",
    "\n",
    "with open('all_forums_tfidf_vector.data', 'wb') as file:\n",
    "    pickle.dump(tfidf_vectors, file)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tfidf_vectorizer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Example #1\n",
    "\n",
    "Both the query post and most similar post talk about Honda Civics and seek help for problems related to the turning off and/or turning on of the car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Post: \n",
      "2012 Honda Civic usually won’t start right up in the morning but always starts after a few tries. Cranks a few times first try and then seems dead, leave key on cranks a few more times and slows to stop, turn key off and back on cranks better like it never happened or does the same thing again. I’m pretty sure the door lock actuator in drivers side is bad not sure if it is parasitic on power to ignition? Please any ideas\n",
      "\n",
      "Most Similar Post: \n",
      "1991 Honda Civic shuts off when I stop sometimes but turns back on…please leave any solutions\n",
      "\n",
      "Similarity Score: 0.21726805949542058\n"
     ]
    }
   ],
   "source": [
    "# Choose random post as query\n",
    "random_index = random.randint(0, tfidf_vectors.shape[0] - 1)\n",
    "query_vector = tfidf_vectors[random_index]\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_scores = cosine_similarity(query_vector, tfidf_vectors).flatten()\n",
    "\n",
    "# Exclude query post itself from recommendations\n",
    "similarity_scores[random_index] = -1\n",
    "\n",
    "# Index of most similar post\n",
    "most_similar_index = np.argmax(similarity_scores)\n",
    "\n",
    "# Recommend the most similar post\n",
    "print(f\"Query Post: {posts_text[random_index]}\")\n",
    "print(f\"Most Similar Post: {posts_text[most_similar_index]}\")\n",
    "print(f\"Similarity Score: {similarity_scores[most_similar_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Example #2\n",
    "\n",
    "Not all the scraped data is in English. In fact, in this example, it can be seen that the posts belong to the same language, namely German. They both mention political movements, some sort of protest/rebellion against authority, and specific topics such as capitalism and nationalism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Post: \n",
      "Die Gelbe Westen Bewegung scheint sich global auszubreiten. In Europa, Nordamerika, Asien wird zur Zeit in gelben Westen demonstriert.\n",
      "Die gelben Westen sind kein homogener Haufen, obwohl sie an Occupy Wallstreet errinern, richtet sich ihr Protest primär gegen die Regierung und nicht gegen das Finanzkapital.\n",
      "Sie wollen weder Kapitalismus, Nationalismus oder Kommunismus, sie wissen meistens überhaupt nicht was sie wollen. Dennoch scheint eine Masse von Menschen in Ländern der ersten und zweiten Welt mit ihren Lebensbedingungen massiv unzufrieden zu sein.\n",
      "Es kann natürlich sein, dass sich das ganze wieder verläuft, aber es gibt auch ein Potential, dass sich dieser Unwille früher oder später politisch artikulieren wird. Wer Politik abseits der etablierten Parteien betreiben möchte, dem empfehle ich sich mit diesem Thema mal auseinanderzusetzen.\n",
      "\n",
      "Most Similar Post: \n",
      "\n",
      "Ich erlaube mir, den Vortrag hier auf Deutsch wiederzugeben, mit einigen Anmerkungen und Erklärungen natürlich.\n",
      "Slavoj Zizek berichtet über einen recht aktuellen Film aus Slowenien, Klassenfeind, dem Heimatland des Philosophen.\n",
      "Dadrin geht es um einen autoritären Deutschlehrer, dem vorgeworfen wird eine Schülerin in den Selbstmord getrieben zu haben. Die Schüler proben einen Aufstand gegen ihren Lehrer, der aber selbst immer autoritärere Züge annimmt. Zumindest fehlt ihnen jeder Beweis das es sich bei dem Lehrer tatsächlich um den Schuldigen hinter dem Selbstmord der Schülerin handelt. Es handelt sich also um eine Art Hexenjagd.\n",
      "Schließlich kommt heraus, dass der Lehrer keinesfalls die Schülerin bedrängt hat, sondern ihr in einem Gespräch lediglich eröffnet hat, dass es ihr Leben ist und sie die alleinige Verantwortung dafür trage, was sie damit anstelle. Die Schülerin kam mit dieser Antwort offensichtlich nicht zurecht oder aber wählte bewußt den Selbstmord.\n",
      "Zizek unterscheidet auf Basis dieses Filmes zwei Arten von Lehrern.\n",
      "Die einen geben ihren Schülern ein System, hinter dem sie sich verstecken können.\n",
      "Sie bezeichnen sich selbst als erleuchtet und geben ihren Schülern das Gefühl, dass sie nur tun müssen was der Lehrer sagt und es wird alles gut werden.\n",
      "Die anderen aber konfrontieren den Schüler mit seiner Freiheit, die aber auch bedeutet sich nicht mehr länger hinter dem Lehrer oder einer anderen Autorität verstecken zu können.\n",
      "Diese radikale Selbstverantwortung bedeutet nicht, dass man seine Umwelt beliebig formen kann. Zizek ist Materialist, er glaubt nicht an Hokuspokus oder irgendwelche metaphysischen Placebos. Nur weil ich meiner Selbstverantwortung bewußt bin, heißt das nicht, dass es mir gelingen wird, das Leben zu leben was ich gerne möchte, trivialerweise könnte das nötige Kleingeld fehlen.\n",
      "Selbst verantwortlich ist also nicht ontologisch zu lesen, sondern rechtsphilosophisch. Es bedeutet, dass es keine zentrale Beschwerdestelle gibt, bei der ich am Ende meines Lebens ein Formular ausfüllen kann, wenn mein Leben anders verlaufen ist als ich es gern hätte und wo ich dann entsprechend ausgezahlt werde. Es bedeutet auch, dass niemand für mich meine Intressen durchsetzen wird, wenn ich es nicht selbst tue.\n",
      "Diese Idee der Freiheit ist für Zizek eine zentrale politische Forderung. Zur Zeit gibt es in Europa 3 tragende gesellschaftliche Gruppen.\n",
      "Konsumismus:\n",
      "Man ist zufrieden mit den kleinen Freiheiten, die einem der Kapitalismus gewährt. Die Freiheit der Wahl beschränkt sich also auf die gesetzlich vorgeschriebenen Urlaubstage und wofür ich das Geld ausgebe, dass ich nicht brauche um die Lebenserhaltungskosten zu bezahlen. Ich kann die Internetseite ansurfen die ich will, ich kann auch den Fernsehkanal ändern, wenn mir das Programm nicht gefällt. Große Entscheidungen fälle ich lieber nicht, sondern überlasse sie den Experten. Oder ich berufe mich auf die Alernativlosigkeit meiner Umstände, ohne überhaupt zu prüfen, ob diese tatsächlich so alternativlos sind, wie sie auf den ersten Blick aussehen.\n",
      "Rechtspopulismus:\n",
      "Der Rechtspopulismus ist eine weitgehend irrationale und wissenschaftsfeindliche Bewegung, die versucht zu einem goldenen Zeitalter des Kapitalismus zu gelangen. Dieser wird in der Regel in der Vergangenheit vermutet und die Rechtspopulisten glauben dementsprechend an die Rückkehr zu alten bewährten Werten (oder was sie dafür halten) gepaart mit einem rücksichtslosen Nationalegoismus.\n",
      "Sie sind dabei auch nicht gewillt, die von ihnen benutzten Schlagwörter mit irgendwelchen Theorien oder durchdachten Programmen zu untermauern. Trump hat es sogar geschafft mit offener Inkompetenz zu punkten. Kurioserweise sind diese Verteidiger Europas bzw. des Abendlandes also eigentlich Saboteure der Werte, die den Westen im Kern ausmachen, es handelt sich bei ihrer Aufklärung bestenfalls um eine vulgär-Aufklärung.\n",
      "Pseudo-Linke:\n",
      "Fukuyama rief in den 90ern das Ende der Geschichte aus. Viele der “Pseudo-linken”, wie Zizek sie nennt, haben sich mit dem Kapitalismus abgefunden und versuchen ihn mit kleinen Reförmchen ein menschliches Anlitz zu verleihen. Dies mißlingt zunehmend, trotz aller oberflächlicher Bemühungen für Rechte von Minderheiten, steigt der Druck durch den Kapitalismus auf den einzelnen zunehmend. Ein Blick auf die Zahlen genügt, Arbeitenehmerrechte werden zunehmend abgebaut, der Sozialstaat sowieso. Die “Pseudo-linken” sind nicht an ernsthafter politischer Arbeit intressiert, sondern vor allen Dingen an der Befriedigung ihres politisch korrekten Gewissens, also an symbolischen Taten, die kein wirkliches Gewicht haben. Statt echtem Arbeitskampf wollen sie sich also bloß als gute Menschen fühlen, es ist vielmehr eine Art Lifestyle, eine politische Vision fehlt vollkommen und viele ihrer Ideale wie Basisdemokratie funktionieren nicht richtig.\n",
      "Die Linken sind dabei die eigentlichen Wächter der Moral, dies war schon immer ihre historische Aufgabe.\n",
      "Wenn wir also keinen Kapitalismus mit asiatischen Werten wollen (das heißt eine Art Neofeudalismus!), muß sich die europäische Linke mal in Bewegung setzen und schnellstmöglich neue Konzepte ausarbeiten, sonst landen wir in einem neuen geistigen Mittelalter.\n",
      "Soweit spricht Zizek.\n",
      "\n",
      "Similarity Score: 0.6084559153035275\n"
     ]
    }
   ],
   "source": [
    "# Choose random post as query\n",
    "random_index = random.randint(0, tfidf_vectors.shape[0] - 1)\n",
    "query_vector = tfidf_vectors[random_index]\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_scores = cosine_similarity(query_vector, tfidf_vectors).flatten()\n",
    "\n",
    "# Exclude query post itself from recommendations\n",
    "similarity_scores[random_index] = -1\n",
    "\n",
    "# Index of most similar post\n",
    "most_similar_index = np.argmax(similarity_scores)\n",
    "\n",
    "# Recommend the most similar post\n",
    "print(f\"Query Post: {posts_text[random_index]}\")\n",
    "print(f\"Most Similar Post: {posts_text[most_similar_index]}\")\n",
    "print(f\"Similarity Score: {similarity_scores[most_similar_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Example #3\n",
    "Both posts are philosophical discussions relating to values and ethics in which utilitarianism and consequentialism are brought up, and both authors discuss the future and what they consider themselves to be at the present stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Post: \n",
      "\n",
      "question_everything.jpg1024×768 238 KB\n",
      "\n",
      "I used to be a utilitarian. Now I have become mostly uncertain. I’ve pondered about my uncertainty so much that I decided that it was the only thing that was constant and that could give me a kind of stability. Uncertainty was the only basis I could use to get somewhere. Epistemological consequentialism (EC) is the philosophy I’m currently trying to shape on that basis. But first of all, let’s consider utilitarianism first and then move on to why I started getting doubts.\n",
      "Utilitarianism\n",
      "Utilitarianism is an altruistic consequentialist normative ethical philosophy that aims to optimize utility as defined by some kind or set of non-negative mental state(s). Since there are many different kinds and sets of non-negative mental state(s) there are different strands of utilitarianism – see below. My definition here is a bit of a monster, so we need to break it down a bit:\n",
      "\n",
      "\n",
      "Altruisitic means that people should care about more than their own personal self, but also about other sentient entities and include their mental states in their ethical considerations\n",
      "\n",
      "Consequentialist means that what counts are the consequences of actions, and nothing else – at least everything else being the same\n",
      "\n",
      "Normative means that utilitarianism is not so much a theory about human behaviour, but a set of statements about how humans should behave\n",
      "\n",
      "Ethical means it’s about ideal moral behaviour, which is usually behaviour in a social context\n",
      "\n",
      "Philosophy means that it’s some real abstract and intellectual stuff that we don’t really know how to approach with the scientific method\n",
      "\n",
      "Optimization of utility can mean maximizing positive utility or minimizing negative utility (which corresponds to negative utilitarianism) or both at the same time (which corresponds to classical utilitarianism)\n",
      "\n",
      "Utility is usually thought of something that can be quantified, or at least treated with some kind of mathematical formalism – in the very least we want to be able to sometimes be able to say whether something has more utility than something else\n",
      "\n",
      "Non-negative mental states can be anything among more specific concepts like\n",
      "Happiness (-> Hedonistic Utilitarianism)\n",
      "Well-being (->Eudaimonic Utilitarianism)\n",
      "Satisfaction of subjective preferences (-> Preference Utilitarianism)\n",
      "Satisfaction of subjective desires (-> Desire Utilitarianism)\n",
      "Subjective qualia with positive valence (-> Valence Utilitarianism)\n",
      "\n",
      "Using this terminology, I classified myself as classical valence utilitarian. Qualia are subjective perceptional impressions, the “how it feels like” aspects of perceiving something, for example the colour blue, or being hungry, or having a seemingly clever idea. The valence of a quale is the “how good it feels like” aspect of it. Does it feel good? Do I want more of it? Does it feel bad? Do I want to avoid it? Someone aware of the recent findings in neuroscience and psychology might notice that these questions may touch on the distinction between the “liking” and “wanting” systems of the human mind. Making this distinction complicates matters even more, and I don’t see a good reason to digress into this direction here.\n",
      "In a very simplistic and raw terminology utilitarianism is about “making everyone feel really good”. Making sentient beings feel better (all other things being equal) is the ethical correct way to act, according to utilitarianism, and doing the opposite is bad. This line of thinking does seem to make a lot of sense and has intuitive and emotional appeal. That alone doesn’t make it objectively correct, however. So, let’s come to my issues with utilitarianism:\n",
      "My issues with utilitarianism\n",
      "First of all, I'm not saying that utilitarianism was wrong or anything like that. I still believe that, if anything, it is probably, on a very abstract level, very close to being an aspect of ethical truth. My thinking goes more into the direction that utilitarianism might be a premature philosophy that could be refined into something better, though I'm not sure what this better philosophy or theory might look like.\n",
      "Not everyone is a utilitarian\n",
      "A very general argument against utilitarianism (which actually applies to every other ethical philosophy) is that not everyone accepts utilitarianism as the ethical philosophy we all should adhere to. In the past I used to assume that this rejection stemmed from those people not fully understanding or \"getting\" utilitarianism. After all, in reality utilitarianism is a really abstract and highly complex philosophy, so it's not surprising that not everyone grasps utilitarianism easily. What really made me stop and reconsider my position was the fact that there are actually very intelligent and rational people who seem to understand utilitarianism and at the same time don't accept utilitarianism as their ethical philosophy of choice. They could have chosen to refine utilitarianism in those areas where they disagreed with it, but instead they prefer to choose other ethical philosophies instead. But why? Of course, I could assume that they were all deluded in some way or had ulterior motives for rejecting utilitarianism, but that would be rather extreme position to take. Instead, they might have actually good reasons for their choice. And that possibility is something that at least causes some potential concern for me, even if I actually happen to disagree with all the reasons they actually express.\n",
      "Utilitarianism is kinda complex\n",
      "Next comes the issue that utilitarianism is actually a class of different philosophies, as we have already seen above. Which one is the correct one? And why? The small number of possible versions I've mentioned above is only the tip of the iceberg. There are many different attributes any single version of utilitarianism can possess. So, we would have to pick the right option of each of those dozens, hundreds, or even more attributes to get the \"correct\" version of utilitarianism. The issue that utilitarianism is a philosophy and not a scientific theory makes this observation even worse: How would we able to agree on the right version, even if we all agreed that utilitarianism was the best ethical theory?\n",
      "Utilitarianism struggles with \"big cosmologies\"\n",
      "What is a \"big cosmoslogy\"? This is my own terminology and it basically means any kind of view of the world that implies that the world is essentially infinite and contains at least almost all combinations of anything you can imagine. The physicist Max Tegmark presents different levels of big cosmologies, which he calls [different multiverse levels](http://space.mit.edu/home/tegmark/crazy.html). Also note that there is a philosophical theory called [Modal realism](https://en.wikipedia.org/wiki/Modal_realism) that poses that everything that can possibly exist actually exists somewhere. In some sense, modal realism is a pretty much maximal cosmology. Now it happens that I have reasons for believing modal realism to be true.\n",
      "Anyway, what does this have to do with utilitarianism? There’s a Less Wrong article about how big cosmologies or “big worlds” as they are called there clash with moral sentiments. It points to some issues that big cosmologies cause for your view of subjectivity and what you should expect to happen in the future. But it doesn’t do full justice to this immensely difficult subject. Neither can I in the scope of this post, so let’s just mention some problems:\n",
      "\n",
      "You are too small and insignificant to optimize utility over the whoe multiverse in a big cosmology\n",
      "In a big cosmology you can’t exactly know where you are in the huge multiverse, which makes it difficult to say over which “area” of the multiverse you want to optimize utility – so even if you just want to optimize utility locally it’s even hard to define your “local area” in a meaningful sense\n",
      "Big cosmologies might be so big that they might even blow up the concept of probabilities – and doing utilitarianism without being able to refer to probabilities is pretty much hopeless\n",
      "If about anything that can happen, actually happens somewhere, why even bother, if you can’t really change that fact in hardly any meaningful sense\n",
      "\n",
      "For many years I tried finding a way to make utilitarianism work with modal realism in some most meaningful sense, but I can’t claim to have arrived at a really satisfying solution.\n",
      "The Reparator Paradox\n",
      "The reparator paradox is a problem that arises for classical utilitarianism (but not negative utilitarianism), when we consider the possibility of powerful beings creating simulations that contain sentient beings. This philosophical problem overlaps with the theological problem of theodicy. If you are interested in such kind of though experiments, you should read my post:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Reparator Paradox Philosophy\n",
      "\n",
      "\n",
      "    Over the last month I seemed to have stumbled upon a deeply worrying philosophical issue that I now call the reparator paradox. I’ve already explained reparationism (previously called compensationism) in the post “Four posthuman ethical frameworks”, and also mentioned it in the post “Principles of the Aonian Exaltation”, where it’s briefly described as this, with the words in [brackets] being optional: \n",
      "\n",
      "If you cause suffering to other sentient beings, you are obliged to \n",
      "compensate for that by …\n",
      "  \n",
      "\n",
      "The reparator paradox made me doubt that “conventional utilitarianism” is an actually robust philosophy that provides clear meaning and orientation.\n",
      "Utilitarianism is about mental states, which we don't really understand\n",
      "We don't really understand how our brains create the thoughts and feelings that we experience. Even worse: We don't actually know on a solid level what thoughts and feelings actually *are*. So, how can we try to optimize something when we don't even know what that thing is that we are trying to optimize? At this point, we don't have much more than appeals to intuition.\n",
      "It would be great, if science could solve those mysteries, but at the moment we are not at this stage, so it’s a bit dubious to base our current ethical reasoning on something that we don’t understand now. If anything, this means that utilitarianism should be an ethical system for the future, but not the present.\n",
      "Humans are bad at predicting the future, especially future mental states\n",
      "Humans aren't great at predicting the consequences of their actions. Especially when they concern the distant future via indirect effects. And humans are even worse when it comes to estimating the impact of about anything on their emotional states. So, even if utilitarianism was a good thing in theory, it is questionable whether letting humans get in contact with something intellectually demanding as utlitarianism would work fine in practice. Utilitarianism didn't even work fine for me on a personal level. Ironically, I generally seem to do better when I actually try to seek suffering rather than happiness, but that might just be me.\n",
      "Meta-ethics\n",
      "So, if utilitarianism isn't the best ethical philosophy there is, what is it then? Is there even something like a \"right\" ethical philosophy? Are there even \"ethical truths\" at all? This is where we enter the realm of meta-ethics, which is about such meta-questions about ethical reasoning:\n",
      "\n",
      "\n",
      "en.wikipedia.org\n",
      "\n",
      "\n",
      "Meta-ethics\n",
      "Meta-ethics is the branch of ethics that seeks to understand the nature of ethical properties, statements, attitudes, and judgments. Meta-ethics is one of the three branches of ethics generally studied by philosophers, the others being normative ethics and applied ethics.\n",
      " While normative ethics addresses such questions as \"What should I do?\", evaluating specific practices and principles of action, meta-ethics addresses questions such as \"What is goodness?\" and \"How can we tell what is good from ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Meta-ethics has its own complex terminologies and stuff, which might be enlightening, but also confusing. Instead, I want to approach the issue from the following question: What are values?\n",
      "A dynamic ontology of values\n",
      "A value is basically a system of thoughts. Such thought systems in their full generality are called [memes](https://en.wikipedia.org/wiki/Meme), a term that was coined by Richard Dawkins. Let's just say that values are a special kinds of memes.\n",
      "In that framework we can ask how values evolve, especially ethical values. Perhaps applying systems theory would enlighten us about how values interact and change. At the moment, it is apparent that different people have quite different values, but occasionally people agree with one another on certain values for one reason or another. Those reasons could be interpreted as attractive forces that draw the value sets of different people together. Of course, there could also be repelling forces that make people reject certain values they don’t hold themselves.\n",
      "The question is, whether in the long run the attractive forces triumph over the repelling forces, so that at the end everyone arrives at the same set of ethical values: A terminal ethical philosophy (TEP). In the language of systems theory such a TEP would be an attractor. It attracts the value systems of people to itself. The process with which people would arrive at a TEP might be quite complex and might even take aeons, but it would work.\n",
      "Now, there are deeper questions like: Is there a TEP at all, and if yes, is there a single TEP, or multiple TEPs, in which case it would depend on the starting conditions at which TEP people would end up. Well, at the moment we don’t know which is the case. And we don’t know whether we even can know what is the case.\n",
      "Meta-ethical optimism\n",
      "Anyway, I am subscribing to a position that I call \"meta-ethical optimism\". I hope that there is a *single TEP* and that we will arrive at it eventually. Note that I've written \"I hope\", not \"I believe\". It might very well be the case that there are multiple TEPs, or no TEPs at all, or that it would take an infinite time to actually arrive at a TEP. Those are possibilities that I don't like, which makes me hope that they are actually wrong.\n",
      "So, what follows from meta-ethical optimism? At this stage, not very much. But on the basis of meta-ethical optimism I propose an ethical philosophy called epistemological consequentialism.\n",
      "Epistemological Consequentialism\n",
      "Epistemology is the study of knowledge and justified belief:\n",
      "\n",
      "\n",
      "en.wikipedia.org\n",
      "\n",
      "\n",
      "\n",
      "Epistemology\n",
      "\n",
      " Related concepts and fundamentals:\n",
      " Epistemology (/ɪˌpɪstɪˈmɒlədʒi/ (listen); from Greek  ἐπιστήμη, epistēmē, meaning 'knowledge', and  -logy) is the branch of philosophy concerned with the theory of knowledge.\n",
      " Epistemology is the study of the nature of knowledge, justification, and the rationality of belief. Much debate in epistemology centers on four areas: (1) the philosophical analysis of the nature of knowledge and how it relates to such concepts as truth, belief, and justification, (2) v...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In the context of what I’ve written so far, the idea is to find out how to study the “value space” in which might find a TEP. If we find out how to do that, we could use this kind of epistemological theory to bring people closer to a TEP, if it exists.\n",
      "Epistemological consequentialism (EC) is a kind of provisional ethical philosophy that states that we should actively seek a TEP, ideally in the hope that it’s unique and that it doesn’t take an eternity to get close to it.\n",
      "Note that my suggested ethical philosophy of epistemological consequentialism should not be confused with the epistemological philosophy of epistemic consequentialism!\n",
      "In epistemological consequentialism what has value is first and foremost improving our ability to probe value space, in the hope to obtain reliable knowledge about “actually ideal” ethics.\n",
      "Prescriptions from epistemological consequentialism\n",
      "Epistemological consequentialism can be seen as normative ethical philosophy in its own. In that case, it's natural to ask what it prescribes us to do. What should we do if we accept EC as our ethical guidelines, even if just as provisional ethical system?\n",
      "That’s pretty much an unexplored question, because I’ve only come up with EC recently. Its name implies that it’s a form of consequentialism, but it’s not a form of utlitarianism (at least not obviously so)! Instead of seeking non-negative mental states we seek knowledge, or even wisdom. One might be inclined to classify them as non-negative mental states, but it’s not about experiencing knowledge and wisdom, but about possessing them.\n",
      "Anyway, there are many open questions that we need to get clarity about to arrive at any definite prescriptions of EC. Let’s simplify the terminology in so far as that we call that which EC wants to optimize “wisdom”. Then a natural question is: Whose wisdom should we optimize? In an egoist version of EC it would be about one’s own wisdom. An altruist version would instead be about the “general wisdom” of society (perhaps seen as some kind of global meta-mind). Apparently, egoistic and altruistic versions of EC would come to quite different conclusions about what actions to prescribe.\n",
      "In any case, a natural prescription would be to become more knowledgable, learn more about epistemology, and especially about values. If possible and useful, one should also try to become more intelligent and wise. That would be a possible justification for transhumanism – or just of the intelligence enhancing aspect of that philosophy.\n",
      "Issues with epistemological consequentialism\n",
      "A big problem with EC is that it doesn't provide much of an orientation at first. It's not clear how it relates to other ethical philosophies that are less \"meta\". EC is the philosophy that might lead us to **the one TEP**, but before we have reached that goal, our only orientation is to move along a path towards a TEP.\n",
      "From where do we start that journey? It might seem reasonable to start from the values we’ve had so far. But would we have a reason to reject those along the way, as we gained more wisdom? Probably. Also, what if one decides to be an adherent of EC and nothing else, rejecting all non-EC derived values from the start, if that’s even possible? Increasing wisdom would be the only maxim such a person would subject oneself to. In how far would such a philosophy be compatible with conventional moral reasoning and actions? Would such a “pure” version of EC have to be moderated with elements of other ethical philosophies?\n",
      "At the moment I’m quite uncertain about how to answer those questions, but at least I realize that those are important questions nevertheless that deserve at least some attention.\n",
      "Epistemological consequentialism might be a terminal ethical philosophy in its own right\n",
      "If it is not the case that there is a single TEP that we can arrive at in a finite amount of time, then things might turn out a bit bizarre. We might be on an eternal journey for a truth that doesn't exist. Manoeuvring value space without finding any save harbour – other than EC itself! In fact, if that is the case, it might turn out that EC is some kind of strange attractor that might be classified as terminal ethical philosophy in its own right!\n",
      "Why even bother?\n",
      "One could simply decide that all of this is way to \"meta\" and that this emphasis on our lack of agreement and our uncertainty about ethical truth is taken much to seriously. Why not simply choose a value system and stick with it, regardless whether it's \"true\" or whether the \"truthfulness\" of a value system is even a meaningful concept? While there are of course problems with such a position, I can see its appeal. There are of course deep issues surrounding this question, which will need to be addressed sooner or later.\n",
      "Final remarks\n",
      "\n",
      "I probably have raised more questions than I could answer. Well, that’s philosophy for you \n",
      "\n",
      "I am not sure whether I want to classify myself as utilitarian or epistemological consequentialist, especially at this stage where I don’t know what EC actually implies\n",
      "My current knowledge about epistemology is not very comprehensive – I probably need to learn more about that subject\n",
      "I have written this out of a subjective sense of frustration, confusion, and even depression – I have written on this post for almost 4 hours straight and past my regular bed-time\n",
      "I apparently can’t simply stop being a philosopher, even if there are other important things I should (perhaps) do\n",
      "\n",
      "\n",
      "Most Similar Post: \n",
      "One can define transhumanism as the philosophy that aims at improving the human condition with science and technology. Formulated that way, it is actually an incomplete philosophy, because it doesn’t specify what is “good”, “better”, or “improvement”. In other words, the core philosophy of transhumanism needs to be complemented with a philosophy that tells you what is “good”. This is what ethics is all about, at least in the context of what is good in a social context.\n",
      "There are three main classes of ethical philosophies:\n",
      "\n",
      "\n",
      "Virtue ethics that focuses on the character of persons and defines the good as good character traits aka virtues. Thus, virtue transhumanism would aim at improving the character of humans by technology. This is consistent with efforts under the label of “moral enhancement”.\n",
      "\n",
      "Deontology is concerned with rules guiding good behaviour. If people behave according to certain ethical rules, their actions are good, otherwise they are bad. A deonological transhumanism would probably aim to increase the ability of humans to follow certain rules. Framed more positively, deontological transhumanism wants to make humans more rational and intelligent, so that they can make better decisions. The goal of intelligence enhancement makes sense through and through when seen through the lens of deontological transhumanism. Also related is the idea of artificial (general) intelligence which should help us solve difficult problems. Interestingly, there are efforts to create “friendly AI” that is programmed so that it can only act in ways which are beneficial for humanity. Note that without an ethical frame the question of what is “beneficial” isn’t clearly defined, either. But with a deontological frame, friendly AI would have to follow stricter ethical rules (something like “Asimov’s laws of robotics on steroids”) than normal humans are supposed to follow.\n",
      "\n",
      "Consequentialism defines good acts as acts that have good consequences. Now what are good consequences? There are different schools of thought about this question. While consequentialism in general is less inclined on answering this question directly, there is a large ethical philosophy within consequentialism that does provide various answers to this question: Utilitarianism. Utilitarianism is an altruistic consequentialist philosophy, so it’s not about personal good, but good for as much people as possible. It comes in different flavours, each having a different definition of what this “good” is:\n",
      "\n",
      "Hedonistic utilitarianism is based on the idea of hedonism: The primary good is simply what we call happiness. What is the best thing for hedonistic utilitarianism? That which maximizes global happiness. Hedonistic utilitarianism was the original form of utilitarianism and also the first version of consequentialism. Hedonistic utilitarian transhumanism is likely to prescribe genetic enhancements which improve the happiness set-point of people. Also the development and use of drugs and implants which make people happier without doing significant harm are promoted by hedonistic utilitarian transhumanism.\n",
      "\n",
      "Preference utilitarianism aims to satisfy preferences of those who actually have preferences. As many preferences as possible should be satisfied, no matter who the “owner” of those preferences is. Interestingly, preference utilitarianism has been taken as prominent basis for arguing for animal rights. For preference utilitarian transhumanists the development of technologies which increase our power over the world would be priority, because those would allow us to align the world to our preferences. Examples for such technologies are atomically precise manufacturing which allows the cheap creation of super high quality goods with incredible properties. In the case that subjective preferences are easily satisfied without the requirement that these preferences refer to the “real world”, the creation of highly realistic and compelling virtual worlds would be a highly valued goals for preference utilitarian transhumanists. Finally, curing ageing and death would be prioritised pretty much, because nobody really wants suffer from ageing and death.\n",
      "\n",
      "Desire utilitarianism is a position that has been formulated, but hasn’t received much attention so far. It’s about the satisfaction of emotional desires rather than “cognitive” preferences. It is also associated with the “wanting” system of the brain, instead of the hedonic “liking” system. In its goals, desire utilitarian transhumanism would be pretty similar to preference utilitarian transhumanism.\n",
      "\n",
      "Eudaimonic utilitarianism focuses on the greek concept of eudaimonia, which some identify with “happiness”, but which rather means holistic well-being or flourishing. In some sense, eudaimonic utilitarianism could be seen as sophisticated and more balanced version of hedonistic utilitarianism. Eudaimonic utilitarian transhumanism would aim to improve the conditions for well-being / flourishing with rational and technological interventions that are suited for that purpose. It’s a priori not clear which these are supposed to be, but it would be a rather scientific endeavour to find out what really increases well-being and what actually makes it less likely. Eudaimonic utilitarian transhumanists are perhaps most eager to aim for a holistic approach to improving the human condition, also focusing on social reforms instead of just focusing on improvements on the level of the individual person.\n",
      "\n",
      "As already mentioned, different ethical ideas seem to be naturally associated with different foci for technological or scientific development if they are combined with the idea of transhumanism. That’s not to say that supporters of these specific schools would exclusively focus on the mentioned technologies. It just means that there are different primary motivations and that some technologies seem to be associated more closely or directly with these motivations.\n",
      "Also, let’s not forget that most people in general don’t know an awful lot about different ethical philosophies and rarely fully subscribe to one of those explicitly. The generic transhumanist is not a clear exception to this rule of thumb. While most transhumanists have clear personal motivations for pursuing transhumanist goals, few of them connect these motivations to deeper philosophical considerations.\n",
      "What about me? I would be best described as eudaimonic utilitarian transhumanist, though I usually self-identify as hedonistic utilitarian for simplicity.\n",
      "Now, what is the deeper point of this little essay? It should demonstrate that there are different flavours of transhumanism which pursue different goals, even though all of them involve science and technology as tools for their own purposes. This diversity of goals is a natural cause of tension between different kinds of transhumanists, which is sometimes more, sometimes less apparent.\n",
      "Finally, transhumanism can not only be complemented by ethical philosophies, but also by ideologies or political philosophies which are not primarily concerned with ethics, for example:\n",
      "\n",
      "Anarchism (yes, there are many different flavours of that, too)\n",
      "Communism\n",
      "Democracy\n",
      "Fascism\n",
      "Libertarianism\n",
      "\n",
      "It should be quite clear that such different schools of specific ideological transhumanism have quite different visions of how their transhumanist utopia would look like.\n",
      "So, transhumanism in itself without being coupled with any specific complementary philosophy should only provide a rather modest level of ideological coherence. Therefore, the expected level of compromising within any party based only on transhumanism should be relatively high. It would be quite natural to expect the emergence of different philosophical wings within transhumanist parties which try to maximize their influence on the politics of the whole party.\n",
      "In fact, the alternative to that would either to split up transhumanist parties into their coherent philosophical wings, which would minimize their overall effectiveness and influence, or not to base transhumanist politics on any coherent and sound philosophical principles, which would just make the party seem directionless and unprincipled. Given these alternatives, it sounds like a reasonable proposal to embrace the partition of transhumanist parties into more or less explicit philosophical wings.\n",
      "I for one, am willing to act as eudaimonic utilitarian transhumanist within the emerging Transhumanist Parties openly and explicitly. Better to be clear on ones principles and goals, and then compromise later, than to start with an ill-defined compromise in the first place.\n",
      "What kind of transhumanist are you or do you want to be?\n",
      "\n",
      "Similarity Score: 0.4872398219610254\n"
     ]
    }
   ],
   "source": [
    "# Choose random post as query\n",
    "random_index = random.randint(0, tfidf_vectors.shape[0] - 1)\n",
    "query_vector = tfidf_vectors[random_index]\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_scores = cosine_similarity(query_vector, tfidf_vectors).flatten()\n",
    "\n",
    "# Exclude query post itself from recommendations\n",
    "similarity_scores[random_index] = -1\n",
    "\n",
    "# Index of most similar post\n",
    "most_similar_index = np.argmax(similarity_scores)\n",
    "\n",
    "# Recommend the most similar post\n",
    "print(f\"Query Post: {posts_text[random_index]}\")\n",
    "print(f\"Most Similar Post: {posts_text[most_similar_index]}\")\n",
    "print(f\"Similarity Score: {similarity_scores[most_similar_index]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
